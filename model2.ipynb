{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"model.ipynb","provenance":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"WU9YYcSJiAtD","executionInfo":{"status":"ok","timestamp":1653515935844,"user_tz":420,"elapsed":1759,"user":{"displayName":"Joyce Huang","userId":"04205349756726206625"}},"outputId":"46213917-ff2f-4395-bcdd-e3f80ac0e978"},"execution_count":5,"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"]}]},{"cell_type":"code","execution_count":6,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"YYH6Tr43f9rt","executionInfo":{"status":"ok","timestamp":1653515935845,"user_tz":420,"elapsed":17,"user":{"displayName":"Joyce Huang","userId":"04205349756726206625"}},"outputId":"436e66b3-c994-4ef2-fca7-90cddfafd310"},"outputs":[{"output_type":"stream","name":"stdout","text":["[nltk_data] Downloading package stopwords to /root/nltk_data...\n","[nltk_data]   Package stopwords is already up-to-date!\n"]}],"source":["import os\n","import re\n","import nltk\n","import requests\n","import warnings\n","import pandas as pd\n","import numpy as np\n","import matplotlib.pyplot as plt\n","%matplotlib inline\n","\n","from nltk.corpus import stopwords\n","nltk.download(\"stopwords\")\n","\n","from sklearn.feature_extraction.text import CountVectorizer\n","from sklearn.metrics.pairwise import cosine_similarity\n","\n","from PIL import Image\n","warnings.filterwarnings('ignore')\n","for dirname, _, filenames in os.walk('/content/drive/My Drive/ECE229/data'):\n","    for filename in filenames:\n","        print(os.path.join(dirname, filename))"]},{"cell_type":"code","source":["books = pd.read_csv('/content/drive/My Drive/ECE229/data/Preprocessed_data.csv')\n","print(len(books['book_title'].unique()))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":353},"id":"LLlFfVIIjqMX","executionInfo":{"status":"error","timestamp":1653515935848,"user_tz":420,"elapsed":16,"user":{"displayName":"Joyce Huang","userId":"04205349756726206625"}},"outputId":"63be03c9-ba56-4ff8-ed04-f6456d74f513"},"execution_count":7,"outputs":[{"output_type":"error","ename":"FileNotFoundError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-7-00d6cdb47131>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mbooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/content/drive/My Drive/ECE229/data/Preprocessed_data.csv'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbooks\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'book_title'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munique\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/util/_decorators.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    309\u001b[0m                     \u001b[0mstacklevel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstacklevel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    310\u001b[0m                 )\n\u001b[0;32m--> 311\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    312\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    313\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, error_bad_lines, warn_bad_lines, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options)\u001b[0m\n\u001b[1;32m    584\u001b[0m     \u001b[0mkwds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwds_defaults\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    585\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 586\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    587\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    588\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    480\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    481\u001b[0m     \u001b[0;31m# Create the parser.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 482\u001b[0;31m     \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    483\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    484\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m    809\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"has_index_names\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"has_index_names\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    810\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 811\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    812\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    813\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[0;34m(self, engine)\u001b[0m\n\u001b[1;32m   1038\u001b[0m             )\n\u001b[1;32m   1039\u001b[0m         \u001b[0;31m# error: Too many arguments for \"ParserBase\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1040\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mmapping\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[call-arg]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1041\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1042\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_failover_to_python\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/io/parsers/c_parser_wrapper.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, src, **kwds)\u001b[0m\n\u001b[1;32m     49\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m         \u001b[0;31m# open handles\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 51\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_open_handles\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     52\u001b[0m         \u001b[0;32massert\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandles\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/io/parsers/base_parser.py\u001b[0m in \u001b[0;36m_open_handles\u001b[0;34m(self, src, kwds)\u001b[0m\n\u001b[1;32m    227\u001b[0m             \u001b[0mmemory_map\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"memory_map\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    228\u001b[0m             \u001b[0mstorage_options\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"storage_options\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 229\u001b[0;31m             \u001b[0merrors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"encoding_errors\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"strict\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    230\u001b[0m         )\n\u001b[1;32m    231\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/io/common.py\u001b[0m in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    705\u001b[0m                 \u001b[0mencoding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencoding\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    706\u001b[0m                 \u001b[0merrors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0merrors\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 707\u001b[0;31m                 \u001b[0mnewline\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    708\u001b[0m             )\n\u001b[1;32m    709\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/content/drive/My Drive/ECE229/data/Preprocessed_data.csv'"]}]},{"cell_type":"code","source":["df = books.copy()\n","df.dropna(inplace=True)\n","df.reset_index(drop=True, inplace=True)\n","\n","df.drop(columns = ['Unnamed: 0','location','isbn',\n","                   'img_s','img_m','city','age',\n","                   'state','Language','country',\n","                   'year_of_publication'],axis=1,inplace = True) #remove useless cols\n","\n","df.drop(index=df[df['Category'] == '9'].index, inplace=True) #remove 9 in category\n","\n","df.drop(index=df[df['rating'] == 0].index, inplace=True) #remove 0 in rating\n","\n","df['Category'] = df['Category'].apply(lambda x: re.sub('[\\W_]+',' ',x).strip())\n","\n","df.head(2)"],"metadata":{"id":"msLkNwqziGZA","executionInfo":{"status":"aborted","timestamp":1653515935845,"user_tz":420,"elapsed":9,"user":{"displayName":"Joyce Huang","userId":"04205349756726206625"}}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def item_based_recommender(book_title):\n","    \n","    book_title = str(book_title)\n","    if book_title in df['book_title'].values:\n","    \n","        rating_counts = pd.DataFrame(df['book_title'].value_counts())\n","        rare_books = rating_counts[rating_counts['book_title'] <= 180].index\n","        common_books = df[~df['book_title'].isin(rare_books)]\n","        \n","        if book_title in rare_books:\n","            \n","            random = pd.Series(common_books['book_title'].unique()).sample(2).values\n","            print('There are no recommendations for this book')\n","            print('Try: \\n')\n","            print('{}'.format(random[0]),'\\n')\n","            print('{}'.format(random[1]),'\\n')\n","\n","        else:\n","            user_book_df = common_books.pivot_table(index=['user_id'],\n","                                                    columns=['book_title'],\n","                                                    values='rating')\n","        \n","            book = user_book_df[book_title]\n","            recom_data = pd.DataFrame(user_book_df.corrwith(book). \\\n","                                      sort_values(ascending=False)).reset_index(drop=False)\n","            \n","            if book_title in [book for book in recom_data['book_title']]:\n","                recom_data = recom_data.drop(recom_data[recom_data['book_title'] == book_title].index[0])\n","\n","\n","            low_rating = []\n","            for i in recom_data['book_title']:\n","                if df[df['book_title'] == i]['rating'].mean() < 5:\n","                    low_rating.append(i)\n","                    \n","            if recom_data.shape[0] - len(low_rating) > 5:\n","                recom_data = recom_data[~recom_data['book_title'].isin(low_rating)]\n","            \n","            recom_data = recom_data[0:5]    \n","            recom_data.columns = ['book_title','corr']\n","            \n","            fig, axs = plt.subplots(1, 5,figsize=(18,5))\n","            fig.suptitle('You may also like these books', size = 22)\n","            for i in range(len(recom_data['book_title'].tolist())):\n","        \n","                url = books.loc[books['book_title'] == recom_data['book_title'].tolist()[i],'img_l'][:1].values[0]\n","                im = Image.open(requests.get(url, stream=True).raw)\n","                axs[i].imshow(im)\n","                axs[i].axis(\"off\")\n","                axs[i].set_title('Rating: {}'.format(round(df[df['book_title'] == recom_data['book_title'].tolist()[i]]['rating'].mean(),1)),\n","                             y=-0.18,\n","                                 color=\"red\",\n","                                 fontsize=18)\n","                fig.show()\n","                fig.savefig('foo.png')\n","    else:\n","        print('Cant find book in dataset, please check spelling')                "],"metadata":{"id":"1cso-x69iMvF","executionInfo":{"status":"aborted","timestamp":1653515935845,"user_tz":420,"elapsed":9,"user":{"displayName":"Joyce Huang","userId":"04205349756726206625"}}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["item_based_recommender('To Kill a Mockingbird')\n"],"metadata":{"id":"Q8lKVNNTjMw-","executionInfo":{"status":"aborted","timestamp":1653515935845,"user_tz":420,"elapsed":9,"user":{"displayName":"Joyce Huang","userId":"04205349756726206625"}}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def content_based_recommender(book_title):\n","    \n","    book_title = str(book_title)\n","    if book_title in df['book_title'].values:\n","        rating_counts = pd.DataFrame(df['book_title'].value_counts())\n","        rare_books = rating_counts[rating_counts['book_title'] <= 100].index\n","        common_books = df[~df['book_title'].isin(rare_books)]\n","        \n","        if book_title in rare_books:\n","            \n","            random = pd.Series(common_books['book_title'].unique()).sample(2).values\n","            print('There are no recommendations for this book')\n","            print('Try: \\n')\n","            print('{}'.format(random[0]),'\\n')\n","            print('{}'.format(random[1]),'\\n')\n","\n","        \n","        else:\n","            \n","            common_books = common_books.drop_duplicates(subset=['book_title'])\n","            common_books.reset_index(inplace= True)\n","            common_books['index'] = [i for i in range(common_books.shape[0])]\n","            target_cols = ['book_title','book_author','publisher','Category']\n","            common_books['combined_features'] = [' '.join(common_books[target_cols].iloc[i,].values) for i in range(common_books[target_cols].shape[0])]\n","            cv = CountVectorizer()\n","            count_matrix = cv.fit_transform(common_books['combined_features'])\n","            cosine_sim = cosine_similarity(count_matrix)\n","            index = common_books[common_books['book_title'] == book_title]['index'].values[0]\n","            sim_books = list(enumerate(cosine_sim[index]))\n","            sorted_sim_books = sorted(sim_books,key=lambda x:x[1],\n","                                      reverse=True)[1:6]\n","            \n","            books = []\n","            for i in range(len(sorted_sim_books)):\n","                books.append(common_books[common_books['index'] == sorted_sim_books[i][0]]['book_title'].item())\n","\n","            \n","            fig, axs = plt.subplots(1, 5,figsize=(18,5))\n","            fig.suptitle('You may also like these books', size = 22)\n","            for i in range(len(books)):\n","        \n","                url = common_books.loc[common_books['book_title'] == books[i],'img_l'][:1].values[0]\n","                im = Image.open(requests.get(url, stream=True).raw)\n","                axs[i].imshow(im)\n","                axs[i].axis(\"off\")\n","                axs[i].set_title('Rating: {}'.format(round(df[df['book_title'] == books[i]]['rating'].mean(),1)),\n","                             y=-0.18,\n","                                 color=\"red\",\n","                                 fontsize=18)\n","                fig.show()\n","                     \n","    else:\n","        \n","        print('Cant find book in dataset, please check spelling')"],"metadata":{"id":"6bB_b0_Pk8Ck","executionInfo":{"status":"aborted","timestamp":1653515935846,"user_tz":420,"elapsed":10,"user":{"displayName":"Joyce Huang","userId":"04205349756726206625"}}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["content_based_recommender('To Kill a Mockingbird')"],"metadata":{"id":"4-s4yclnocDR","executionInfo":{"status":"aborted","timestamp":1653515935846,"user_tz":420,"elapsed":10,"user":{"displayName":"Joyce Huang","userId":"04205349756726206625"}}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def custom_recommender(book_title):\n","    \n","    #ITEM-BASED\n","    book_title = str(book_title)\n","    if book_title in df['book_title'].values:\n","    \n","        rating_counts = pd.DataFrame(df['book_title'].value_counts())\n","        rare_books = rating_counts[rating_counts['book_title'] <= 180].index\n","        common_books = df[~df['book_title'].isin(rare_books)]\n","        \n","        if book_title in rare_books:\n","            \n","            random = pd.Series(common_books['book_title'].unique()).sample(2).values\n","            print('There are no recommendations for this book')\n","            print('Try: \\n')\n","            print('{}'.format(random[0]),'\\n')\n","            print('{}'.format(random[1]),'\\n')\n","        \n","        else:\n","            user_book_df = common_books.pivot_table(index=['user_id'],\n","                                                    columns=['book_title'], values='rating')\n","        \n","            book = user_book_df[book_title]  \n","            recom_data = pd.DataFrame(user_book_df.corrwith(book). \\\n","                                      sort_values(ascending=False)).reset_index(drop=False)\n","\n","            if book_title in [book for book in recom_data['book_title']]:\n","                recom_data = recom_data.drop(recom_data[recom_data['book_title'] == book_title].index[0])\n","                \n","            low_rating = []\n","            for i in recom_data['book_title']:\n","                if df[df['book_title'] == i]['rating'].mean() < 5:\n","                    low_rating.append(i)\n","                    \n","            if recom_data.shape[0] - len(low_rating) > 5:\n","                recom_data = recom_data[~recom_data['book_title'].isin(low_rating)]\n","            \n","            recom_data = recom_data[0:1]    \n","            recom_data.columns = ['book_title','corr']\n","            recommended_books = []\n","            for i in recom_data['book_title']:\n","                recommended_books.append(i)\n","                \n","            df_new = df[~df['book_title'].isin(recommended_books)]\n","\n","            #CONTENT-BASED (Title, Author, Publisher, Category)\n","            rating_counts = pd.DataFrame(df_new['book_title'].value_counts())\n","        \n","            rare_books = rating_counts[rating_counts['book_title'] <= 100].index\n","    \n","            common_books = df_new[~df_new['book_title'].isin(rare_books)]\n","            common_books = common_books.drop_duplicates(subset=['book_title'])\n","            common_books.reset_index(inplace= True)\n","            common_books['index'] = [i for i in range(common_books.shape[0])]   \n","            target_cols = ['book_title','book_author','publisher','Category']\n","            common_books['combined_features'] = [' '.join(common_books[target_cols].iloc[i,].values) for i in range(common_books[target_cols].shape[0])]\n","            cv = CountVectorizer()\n","            count_matrix = cv.fit_transform(common_books['combined_features'])\n","            cosine_sim = cosine_similarity(count_matrix)\n","            index = common_books[common_books['book_title'] == book_title]['index'].values[0]\n","            sim_books = list(enumerate(cosine_sim[index]))\n","            sorted_sim_books = sorted(sim_books,key=lambda x:x[1],reverse=True)[1:2]\n","            \n","            books = []\n","            for i in range(len(sorted_sim_books)):\n","                books.append(common_books[common_books['index'] == sorted_sim_books[i][0]]['book_title'].item())\n","\n","\n","            for i in books:\n","                recommended_books.append(i)\n","            \n","            df_new = df_new[~df_new['book_title'].isin(recommended_books)]\n","            \n","            #CONTENT-BASED (SUMMARY)\n","            rating_counts = pd.DataFrame(df_new['book_title'].value_counts())\n","            rare_books = rating_counts[rating_counts['book_title'] <= 100].index\n","            common_books = df_new[~df_new['book_title'].isin(rare_books)]\n","            \n","            common_books = common_books.drop_duplicates(subset=['book_title'])\n","            common_books.reset_index(inplace= True)\n","            common_books['index'] = [i for i in range(common_books.shape[0])]\n","            \n","            summary_filtered = []\n","            for i in common_books['Summary']:\n","                i = re.sub(\"[^a-zA-Z]\",\" \",i).lower()\n","                i = nltk.word_tokenize(i)\n","                i = [word for word in i if not word in set(stopwords.words(\"english\"))]\n","                i = \" \".join(i)\n","                summary_filtered.append(i)\n","            \n","            common_books['Summary'] = summary_filtered\n","            cv = CountVectorizer()\n","            count_matrix = cv.fit_transform(common_books['Summary'])\n","            cosine_sim = cosine_similarity(count_matrix) \n","            index = common_books[common_books['book_title'] == book_title]['index'].values[0]\n","            sim_books = list(enumerate(cosine_sim[index]))\n","            sorted_sim_books2 = sorted(sim_books,key=lambda x:x[1],reverse=True)[1:4]\n","            sorted_sim_books = sorted_sim_books2[:2]\n","            summary_books = []\n","            for i in range(len(sorted_sim_books)):\n","                summary_books.append(common_books[common_books['index'] == sorted_sim_books[i][0]]['book_title'].item())\n","\n","            for i in summary_books:\n","                recommended_books.append(i)\n","                \n","            df_new = df_new[~df_new['book_title'].isin(recommended_books)]\n","            \n","            #TOP RATED OF CATEGORY\n","            category = common_books[common_books['book_title'] == book_title]['Category'].values[0]\n","            top_rated = common_books[common_books['Category'] == category].groupby('book_title').agg({'rating':'mean'}).reset_index()\n","            \n","            if top_rated.shape[0] == 1:\n","                recommended_books.append(common_books[common_books['index'] == sorted_sim_books2[2][0]]['book_title'].item())\n","                \n","            else:\n","                top_rated.drop(top_rated[top_rated['book_title'] == book_title].index[0],inplace=True)\n","                top_rated = top_rated.sort_values('rating',ascending=False).iloc[:1]['book_title'].values[0]\n","                recommended_books.append(top_rated)\n","                \n","            fig, axs = plt.subplots(1, 5,figsize=(18,5))\n","            fig.suptitle('You may also like these books', size = 22)\n","            for i in range(len(recommended_books)):\n","\n","                url = df.loc[df['book_title'] == recommended_books[i],'img_l'][:1].values[0]\n","                im = Image.open(requests.get(url, stream=True).raw)\n","                axs[i].imshow(im)\n","                axs[i].axis(\"off\")\n","                axs[i].set_title('Rating: {}'.format(round(df[df['book_title'] == recommended_books[i]]['rating'].mean(),1)),\n","                             y=-0.18,\n","                                 color=\"red\",\n","                                 fontsize=18)\n","                fig.show()     \n","\n","    else:\n","        print('Cant find book in dataset, please check spelling')             "],"metadata":{"id":"18NdWQzKoexQ","executionInfo":{"status":"aborted","timestamp":1653515935846,"user_tz":420,"elapsed":10,"user":{"displayName":"Joyce Huang","userId":"04205349756726206625"}}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["custom_recommender('To Kill a Mockingbird')\n"],"metadata":{"id":"xnBaKX0wqSwM","executionInfo":{"status":"aborted","timestamp":1653515935846,"user_tz":420,"elapsed":9,"user":{"displayName":"Joyce Huang","userId":"04205349756726206625"}}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import nltk\n","nltk.download('punkt')"],"metadata":{"id":"7q1SBljqqhyh","executionInfo":{"status":"aborted","timestamp":1653515935847,"user_tz":420,"elapsed":10,"user":{"displayName":"Joyce Huang","userId":"04205349756726206625"}}},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Compare all three"],"metadata":{"id":"5eQ1X64yrr-i"}},{"cell_type":"code","source":["item_based_recommender('Harry Potter and the Order of the Phoenix (Book 5)')"],"metadata":{"id":"mUBR4aJpr1Qz","executionInfo":{"status":"aborted","timestamp":1653515935847,"user_tz":420,"elapsed":10,"user":{"displayName":"Joyce Huang","userId":"04205349756726206625"}}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["content_based_recommender('Harry Potter and the Order of the Phoenix (Book 5)')"],"metadata":{"id":"MGxwpCOfr-dj","executionInfo":{"status":"aborted","timestamp":1653515935847,"user_tz":420,"elapsed":10,"user":{"displayName":"Joyce Huang","userId":"04205349756726206625"}}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["custom_recommender('Harry Potter and the Order of the Phoenix (Book 5)')"],"metadata":{"id":"1ZeBYBO5rdO2","executionInfo":{"status":"aborted","timestamp":1653515935847,"user_tz":420,"elapsed":10,"user":{"displayName":"Joyce Huang","userId":"04205349756726206625"}}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[""],"metadata":{"id":"r6tZBmLksC3-","executionInfo":{"status":"aborted","timestamp":1653515935848,"user_tz":420,"elapsed":11,"user":{"displayName":"Joyce Huang","userId":"04205349756726206625"}}},"execution_count":null,"outputs":[]}]}